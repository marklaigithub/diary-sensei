# AI 委員會 QA 流程設計
日期：2026-02-25
專案：diary-sensei（通用化設計，可套用到其他專案）

## 核心理念

不同 AI 模型的偏見方向不同——利用這個差異來找盲點。
不是取代人的判斷，而是把人的角色從「想到所有邊界」變成「在已浮現的分歧中做選擇」。

## 驗證過的模型特性

基於 2026-02-25 實驗結果：

| 模型 | 家族 | 強項 | 適合的角色 | M1 速度 |
|------|------|------|-----------|---------|
| Claude Haiku | Anthropic | 表面 UX 問題、直覺反應 | 初次使用者、手殘使用者 | 即時 |
| Claude Sonnet | Anthropic | 深度技術分析、code review | QA、PM、多語言專家 | 即時 |
| Claude Opus | Anthropic | 設計質疑、安全稽核 | 產品懷疑者、隱私稽核 | 即時 |
| llama3.2:3b | Meta | 直覺 UX、功能缺口發想 | 粗心使用者、功能建議 | 25-167s |
| phi4-mini | Microsoft | 系統一致性、跨功能問題 | 一致性檢查、邊界偵測 | 34-106s |
| mistral:7b | Mistral AI | 合規、教育觀點、自動存檔等「常識」需求 | 合規檢查、UX 常識 | 49-92s |
| gemma2:9b | Google | 長期策略、產品方向 | 重度使用者、產品策略 | 96-289s |

## 流程三階段

### Phase 1：發散（找分歧）

**觸發時機**：
- 完成一個功能模組後
- 版本交付前（v0.x.0）
- 重大設計決策前

**執行方式**：

**Claude 側（並行，讀程式碼）**：
1. spawn 3-6 個 Claude agents，每個給不同角色 persona
2. 每個 agent 讀實際程式碼，從角色視角列出問題
3. 推薦組合：
   - 必選：Sonnet QA（找技術 bug）
   - 必選：Haiku 初次使用者（找 UX 問題）
   - 按需：Sonnet 重度使用者（效能/長期問題）
   - 按需：Opus 設計質疑（架構/安全）
4. 成本約等於 1-2 次 Opus 呼叫

**Ollama 側（依序，只看 app 描述）**：
1. 準備 app 描述（不含程式碼，模擬真實使用者視角）
2. 用 curl 呼叫每個模型，給相同角色和問題
3. 推薦組合：
   - 必選：llama3.2:3b（最接近「不讀說明書的使用者」）
   - 必選：mistral:7b（最全面的「常識」視角）
   - 按需：phi4-mini（一致性檢查）
   - 按需：gemma2:9b（長期策略，但最慢）
4. 成本：免費（本地模型），但耗時 15-30 分鐘

**關鍵設計**：
- Claude agents 看程式碼 → 找到「怎麼壞的」
- Ollama models 看 app 描述 → 找到「使用者覺得怪的」
- 這個資訊不對稱是刻意的

### Phase 2：收斂（找共識與分歧）

**處理方式**：

1. **交叉比對**：列出所有發現，標記每個發現被多少來源提及
2. **分層**：
   - Tier 1（5+ 來源提及）→ 確定要處理，不需投票
   - Tier 2（2-4 來源提及）→ 需要人確認優先級
   - Tier 3（僅 1 來源提及）→ 可能是獨特洞察或噪音，需要驗證
3. **分歧識別**：找出不同來源對同一問題有不同看法的地方
   - 同一 bug 的不同解法（修 vs 重設計）
   - 對同一功能的不同評價（好 vs 壞）
   - 不同層次的關注（技術 vs 法規 vs 教育）

**產出**：
- 測試情境清單（分層 + 分類）
- 分歧清單（需要人裁決）
- 每個情境標記來源（方便追溯）

### Phase 3：裁決（投票 + 人決策）

**自動裁決（不需人介入）**：
- Tier 1 共識 → 直接轉為 issue/task
- 安全問題（任何來源提到）→ 直接修復，不管共識度

**加權投票（半自動）**：
- 按領域相關性加權：

  | 問題類型 | 權重最高的來源 |
  |---------|-------------|
  | UX/初次體驗 | Haiku + llama3.2:3b |
  | 技術 bug | Sonnet QA |
  | 效能/長期使用 | Sonnet 重度使用者 + gemma2:9b |
  | 安全/隱私 | Opus + mistral |
  | 產品設計 | Opus + gemma2:9b |
  | 功能缺口 | llama3.2:3b + mistral |

**人裁決（必須人介入）**：
- 設計方向分歧（修 bug vs 改設計）
- 產品哲學問題（AI 矯正強度等）
- 投入產出比判斷（值不值得做）

## Ollama 模型行為側寫（2026-02-25 實測）

> 基於 diary-sensei 實驗的 25 個回應分析。供未來選模型時參考。
> 原始回應已歸檔至 `~/.claude/02-work/diary-sensei-committee-responses/`

### 整體觀察

- **所有模型成功率都偏低（~20%）**：5 個 persona 通常只有 1-2 個能完整回應
- 主因是 prompt 長度 vs 模型能力的匹配問題——app 描述 + 6 個問題對小模型來說太長
- **建議改進**：未來精簡 prompt 或分批提問，提高完成率

### 各模型特性

| 模型 | 成功率 | 強項 | 弱項 | 風格 |
|------|--------|------|------|------|
| **llama3.2:3b** | 1/5 | 具體場景描述、直覺 UX 痛點 | 缺技術深度、容易 truncate | 使用者口吻，說故事式 |
| **phi4-mini** | 0/5 | （結構化分析的片段可見潛力）| 嚴重的回應長度問題，不適合此任務 | N/A |
| **mistral:7b** | 1/5 | 使用者常識代言：auto-save、視覺提示等直覺期待 | 結構化 persona 時容易 truncate | 專業使用者口吻 |
| **gemma2:9b** | 1/5 | 人格代入最真實、UI 審美意見 | 建議偏模糊、最慢 | 真實使用者抱怨式 |

### 各模型的獨特發現

- **mistral:7b**：唯一提出「auto-save 是關鍵缺失」（使用者常識期待，非技術分析）
- **gemma2:9b**：唯一批評日曆 UI dot 無效（視覺設計層級）
- **llama3.2:3b**：5 秒 undo 的痛感描述最具體（使用者情緒層級）
- **phi4-mini**：不建議使用（0% 完成率）

### 重要澄清：Ollama vs Claude 不是同一維度的比較

> Ollama 模型只看 app 描述（使用者視角），Claude agents 讀實際程式碼（開發者視角）。
> 這個資訊不對稱是刻意設計的——兩者互補，不能直接比「誰比較強」。

| 維度 | Claude agents 的領域 | Ollama models 的領域 |
|------|---------------------|---------------------|
| 安全/架構 | API key 明文、非原子寫入 | — |
| Race condition | stale closure、request guard | — |
| 使用者常識 | — | auto-save、視覺回饋、onboarding |
| 情緒/直覺 | — | undo 太短的挫折感、模式切換困惑 |

mistral 的產出感覺「像人且有洞見」，是因為它代言了使用者常識——
這正是委員會設計中 Ollama 的價值所在，但不代表它的分析能力強於 Opus。

### 選模型建議（依任務）

| 任務 | 首選 | 備選 |
|------|------|------|
| 使用者視角 QA | llama3.2:3b | gemma2:9b |
| 使用者常識檢查 | mistral:7b | — |
| UI/設計評審 | gemma2:9b | — |
| 快速煙霧測試 | llama3.2:3b（最快） | — |
| 完整覆蓋 | mistral + llama3.2（互補） | + gemma2 |

## 成本效益分析

基於 diary-sensei 實驗的實際數據：

| 項目 | 成本 | 產出 |
|------|------|------|
| Claude agents ×6 | ~$2-3 等效 API 費用 | 15+ 技術問題、5 Critical |
| Ollama ×16 查詢 | 免費（本地）+ 25 分鐘 | 4 個 Claude 完全沒發現的問題 |
| 人工整理時間 | 約 30 分鐘 | 20 個結構化測試情境、3 個設計決策點 |

**vs 只用一個 Claude agent**：
- 單一 Sonnet QA agent 大約能找到 60% 的問題
- 委員會多找到的 40% 包含了所有「只有特定視角才能看到的」問題
- 最有價值的 4 個獨特發現都來自非 Claude 模型

## 最小可行版本（MVP）

如果時間/資源有限，最小組合：
1. **Sonnet QA**（必選）— 技術 bug 覆蓋
2. **llama3.2:3b 手殘使用者**（必選）— 最便宜的「不同視角」
3. **人做收斂和裁決**（必選）

這三個就能覆蓋 ~80% 的價值。其他角色按需加入。

## 適用時機

| 情境 | 建議組合 | 原因 |
|------|---------|------|
| 小 bug fix | 不需要委員會 | 成本 > 收益 |
| 單一功能完成 | MVP 版（3 角色）| 快速驗證 |
| 版本交付（v0.x.0）| 完整版（6+ 角色）| 全面覆蓋 |
| 重大設計決策 | Opus + gemma2 + mistral + 人 | 需要多元觀點 |
| 安全稽核 | Opus + mistral + Sonnet QA | 技術 + 法規雙層 |

## 與現有 /review 的整合

委員會 QA 補充現有的 `/review` 分層機制：

| 層級 | 現有 | + 委員會 |
|------|------|---------|
| L0: 自動掃描 | grep patterns | 不變 |
| L1: 結構驗證 | quality-checker (Haiku) | 不變 |
| L2: 深度 review | PM + QA reviewer (Sonnet) | **加入 Ollama 模型作為「使用者代表」** |
| L3: 架構 review | Opus（手動）| **加入 gemma2/mistral 作為「不同視角」** |
| L4: 委員會 QA | **新增** | 完整發散→收斂→裁決流程 |

L4 不是每次都需要，只在版本交付或重大決策時啟動。
